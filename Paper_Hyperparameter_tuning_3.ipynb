{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_type        546 non-null    object \n",
      " 1   Charge_size        546 non-null    float64\n",
      " 2   Standoff_distance  546 non-null    float64\n",
      " 3   Impulse            546 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('IDataset1.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_size        546 non-null    float64\n",
      " 1   Standoff_distance  546 non-null    float64\n",
      " 2   Impulse            546 non-null    float64\n",
      " 3   Charge_type_CompB  546 non-null    uint8  \n",
      " 4   Charge_type_TNT    546 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 14.0 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Charge_type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 4) (546,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset['Impulse']\n",
    "X = dataset.drop('Impulse', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - layers, neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor as KR\n",
    "import math\n",
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chathura Gamage\\AppData\\Local\\Temp\\ipykernel_1372\\2480470563.py:18: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KR(build_fn=create_model, epochs = 500, batch_size = 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_model(n_layers, first_layer_nodes, last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(units = first_layer_nodes,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer = opt, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model = KR(build_fn=create_model, epochs = 500, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 19767.0566 - mae: 105.8644\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17529.9609 - mae: 95.6912\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15107.2334 - mae: 83.7132\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12792.5928 - mae: 72.4762\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10559.8770 - mae: 66.7620\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9215.5771 - mae: 66.5115\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8338.4014 - mae: 66.1615\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7573.6660 - mae: 63.1767\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6911.8809 - mae: 58.8007\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6237.3618 - mae: 54.0460\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5693.1650 - mae: 50.4478\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5161.5635 - mae: 48.5658\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4694.9868 - mae: 47.4415\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4315.1802 - mae: 46.3169\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4022.5942 - mae: 45.7750\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 3758.7434 - mae: 44.9594\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3522.3154 - mae: 43.8854\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3338.8708 - mae: 42.8969\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3144.4204 - mae: 41.5844\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2969.7153 - mae: 40.1722\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2791.8843 - mae: 38.4290\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2635.8306 - mae: 36.7188\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2478.5430 - mae: 35.0241\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2343.4160 - mae: 33.5341\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2200.0129 - mae: 31.9834\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2092.0149 - mae: 30.8529\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1977.5159 - mae: 29.8428\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1877.5221 - mae: 29.1185\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1786.2261 - mae: 28.2404\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1705.4432 - mae: 27.2276\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1606.4222 - mae: 26.5528\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1531.7100 - mae: 25.9913\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1488.9213 - mae: 25.3019\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1369.8037 - mae: 24.3565\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1307.5864 - mae: 23.5325\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1233.8317 - mae: 22.5805\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1159.0922 - mae: 21.8520\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1093.0854 - mae: 21.1684\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1050.8441 - mae: 20.3632\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1002.7577 - mae: 20.1524\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 939.3099 - mae: 19.0145\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 870.3486 - mae: 18.1784\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 821.8584 - mae: 17.6423\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 779.3959 - mae: 17.0789\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 741.0411 - mae: 16.4185\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 713.9067 - mae: 15.9234\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.7177 - mae: 15.3381\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.4630 - mae: 14.9761\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.1968 - mae: 14.6450\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 608.8046 - mae: 14.2658\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.3911 - mae: 13.9714\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 575.1121 - mae: 13.8632\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 576.2780 - mae: 13.9799\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 545.1475 - mae: 13.3194\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 526.5344 - mae: 12.6938\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.1660 - mae: 12.5821\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 512.1537 - mae: 12.4134\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 511.7338 - mae: 12.4337\n",
      "Epoch 59/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 494.8555 - mae: 12.5107\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 481.0999 - mae: 11.7926\n",
      "Epoch 61/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 470.9497 - mae: 11.6500\n",
      "Epoch 62/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 461.0991 - mae: 11.4074\n",
      "Epoch 63/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 467.5506 - mae: 11.4627\n",
      "Epoch 64/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 447.9021 - mae: 11.0453\n",
      "Epoch 65/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 442.4480 - mae: 11.0998\n",
      "Epoch 66/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 442.4499 - mae: 11.0143\n",
      "Epoch 67/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 438.6695 - mae: 11.1573\n",
      "Epoch 68/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 430.2862 - mae: 10.7952\n",
      "Epoch 69/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 409.4944 - mae: 10.0543\n",
      "Epoch 70/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 420.6692 - mae: 10.0857\n",
      "Epoch 71/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 403.0702 - mae: 10.1085\n",
      "Epoch 72/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 402.8087 - mae: 10.1698\n",
      "Epoch 73/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 386.8042 - mae: 9.6438\n",
      "Epoch 74/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 386.7774 - mae: 9.4258\n",
      "Epoch 75/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.4589 - mae: 9.1679\n",
      "Epoch 76/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 373.7804 - mae: 9.2798\n",
      "Epoch 77/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.1696 - mae: 9.2101\n",
      "Epoch 78/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.1850 - mae: 8.9671\n",
      "Epoch 79/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.6795 - mae: 8.9332\n",
      "Epoch 80/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 363.7499 - mae: 8.7504\n",
      "Epoch 81/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.9734 - mae: 8.4694\n",
      "Epoch 82/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 352.5870 - mae: 8.5907\n",
      "Epoch 83/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 347.8024 - mae: 8.4507\n",
      "Epoch 84/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.5592 - mae: 8.3006\n",
      "Epoch 85/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.7083 - mae: 8.3661\n",
      "Epoch 86/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 349.7308 - mae: 8.7879\n",
      "Epoch 87/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 353.2151 - mae: 9.2786\n",
      "Epoch 88/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 342.0812 - mae: 9.0762\n",
      "Epoch 89/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.2408 - mae: 8.3626\n",
      "Epoch 90/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 335.6208 - mae: 8.1796\n",
      "Epoch 91/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 322.9799 - mae: 8.0390\n",
      "Epoch 92/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 328.8349 - mae: 8.1795\n",
      "Epoch 93/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 326.7473 - mae: 7.8580\n",
      "Epoch 94/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 320.5808 - mae: 7.5344\n",
      "Epoch 95/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.7563 - mae: 7.5037\n",
      "Epoch 96/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 317.6700 - mae: 7.4407\n",
      "Epoch 97/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.7136 - mae: 7.5467\n",
      "Epoch 98/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.7434 - mae: 7.6306\n",
      "Epoch 99/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.1147 - mae: 7.3754\n",
      "Epoch 100/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.8978 - mae: 7.3905\n",
      "Epoch 101/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 307.2403 - mae: 7.2720\n",
      "Epoch 102/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.8008 - mae: 7.4827\n",
      "Epoch 103/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 317.9064 - mae: 8.3471\n",
      "Epoch 104/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 316.6116 - mae: 7.8261\n",
      "Epoch 105/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 302.5804 - mae: 7.0767\n",
      "Epoch 106/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 308.5876 - mae: 7.0830\n",
      "Epoch 107/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 301.4394 - mae: 7.1930\n",
      "Epoch 108/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 311.0189 - mae: 7.3434\n",
      "Epoch 109/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 323.9675 - mae: 8.5188\n",
      "Epoch 110/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.7143 - mae: 8.7379\n",
      "Epoch 111/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.0828 - mae: 7.7983\n",
      "Epoch 112/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.0226 - mae: 8.2527\n",
      "Epoch 113/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 305.2607 - mae: 8.3942\n",
      "Epoch 114/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 302.6013 - mae: 8.1600\n",
      "Epoch 115/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 315.2140 - mae: 8.7036\n",
      "Epoch 116/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 312.3337 - mae: 7.7787\n",
      "Epoch 117/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.2004 - mae: 6.9249\n",
      "Epoch 118/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 308.4827 - mae: 7.6331\n",
      "Epoch 119/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.2428 - mae: 7.0207\n",
      "Epoch 120/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 296.4251 - mae: 7.2122\n",
      "Epoch 121/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.2075 - mae: 7.0434\n",
      "Epoch 122/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 288.8948 - mae: 6.7446\n",
      "Epoch 123/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.7359 - mae: 7.1238\n",
      "Epoch 124/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.2704 - mae: 8.0353\n",
      "Epoch 125/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.9039 - mae: 7.4758\n",
      "Epoch 126/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.6666 - mae: 7.0123\n",
      "Epoch 127/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.2288 - mae: 6.5899\n",
      "Epoch 128/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.3647 - mae: 6.5911\n",
      "Epoch 129/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 286.7816 - mae: 6.6710\n",
      "Epoch 130/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.8820 - mae: 6.8368\n",
      "Epoch 131/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.2530 - mae: 7.8424\n",
      "Epoch 132/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.0747 - mae: 9.1340\n",
      "Epoch 133/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 300.9233 - mae: 8.6548\n",
      "Epoch 134/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 290.6448 - mae: 7.4589\n",
      "Epoch 135/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 299.0602 - mae: 7.2369\n",
      "Epoch 136/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 297.3507 - mae: 7.4425\n",
      "Epoch 137/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.7162 - mae: 6.9378\n",
      "Epoch 138/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.5746 - mae: 6.8728\n",
      "Epoch 139/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 286.1324 - mae: 7.1096\n",
      "Epoch 140/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 284.5484 - mae: 6.6483\n",
      "Epoch 141/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.1217 - mae: 6.7993\n",
      "Epoch 142/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.8780 - mae: 6.9828\n",
      "Epoch 143/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.6881 - mae: 7.0088\n",
      "Epoch 144/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.9290 - mae: 7.0223\n",
      "Epoch 145/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.5186 - mae: 7.3704\n",
      "Epoch 146/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.1854 - mae: 7.4975\n",
      "Epoch 147/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.8318 - mae: 8.5255\n",
      "Epoch 148/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.6811 - mae: 9.1562\n",
      "Epoch 149/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.0206 - mae: 7.9820\n",
      "Epoch 150/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 287.6591 - mae: 7.3571\n",
      "Epoch 151/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.8046 - mae: 6.6610\n",
      "Epoch 152/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 291.4237 - mae: 6.7879\n",
      "Epoch 153/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.7869 - mae: 7.6108\n",
      "Epoch 154/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 286.4734 - mae: 7.1486\n",
      "Epoch 155/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.6845 - mae: 6.8080\n",
      "Epoch 156/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.2242 - mae: 6.4119\n",
      "Epoch 157/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.5515 - mae: 6.6134\n",
      "Epoch 158/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 285.0445 - mae: 6.7935\n",
      "Epoch 159/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 283.7124 - mae: 6.8650\n",
      "Epoch 160/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.2822 - mae: 6.5520\n",
      "Epoch 161/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.8061 - mae: 8.2098\n",
      "Epoch 162/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.0046 - mae: 8.7283\n",
      "Epoch 163/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 287.3910 - mae: 8.2479\n",
      "Epoch 164/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.0327 - mae: 7.9245\n",
      "Epoch 165/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.8715 - mae: 6.6846\n",
      "Epoch 166/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.0492 - mae: 6.9371\n",
      "Epoch 167/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.2657 - mae: 6.7766\n",
      "Epoch 168/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 295.1965 - mae: 8.1565\n",
      "Epoch 169/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.7122 - mae: 7.7063\n",
      "Epoch 170/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 281.4882 - mae: 7.2585\n",
      "Epoch 171/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.0381 - mae: 7.5382\n",
      "Epoch 172/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 289.7466 - mae: 7.7398\n",
      "Epoch 173/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 290.3859 - mae: 7.4026\n",
      "Epoch 174/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.8326 - mae: 6.5239\n",
      "Epoch 175/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.0760 - mae: 6.5271\n",
      "Epoch 176/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.0490 - mae: 7.6120\n",
      "Epoch 177/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.7231 - mae: 7.6770\n",
      "Epoch 178/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.5582 - mae: 6.7308\n",
      "Epoch 179/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 286.0465 - mae: 7.4704\n",
      "Epoch 180/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.3201 - mae: 7.0683\n",
      "Epoch 181/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.6968 - mae: 7.7663\n",
      "Epoch 182/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.5060 - mae: 6.9742\n",
      "Epoch 183/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.9819 - mae: 7.3528\n",
      "Epoch 184/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.0871 - mae: 7.5378\n",
      "Epoch 185/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 280.5825 - mae: 7.4133\n",
      "Epoch 186/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.2648 - mae: 6.9803\n",
      "Epoch 187/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 275.1971 - mae: 6.8324\n",
      "Epoch 188/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.9043 - mae: 6.3394\n",
      "Epoch 189/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.2585 - mae: 7.8064\n",
      "Epoch 190/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 285.5522 - mae: 7.3102\n",
      "Epoch 191/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.5860 - mae: 6.5643\n",
      "Epoch 192/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 281.4518 - mae: 6.4496\n",
      "Epoch 193/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.0596 - mae: 6.4383\n",
      "Epoch 194/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 286.6234 - mae: 7.7362\n",
      "Epoch 195/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 286.4699 - mae: 8.1070\n",
      "Epoch 196/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.0558 - mae: 9.0060\n",
      "Epoch 197/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.4505 - mae: 8.9677\n",
      "Epoch 198/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.8347 - mae: 8.3127\n",
      "Epoch 199/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 283.2579 - mae: 7.6783\n",
      "Epoch 200/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 298.2215 - mae: 7.2058\n",
      "Epoch 201/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 282.4343 - mae: 7.5474\n",
      "Epoch 202/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.0540 - mae: 6.8731\n",
      "Epoch 203/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.5282 - mae: 6.5126\n",
      "Epoch 204/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.0467 - mae: 7.0769\n",
      "Epoch 205/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 275.4143 - mae: 6.9095\n",
      "Epoch 206/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 275.6578 - mae: 7.0779\n",
      "Epoch 207/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.4724 - mae: 7.2471\n",
      "Epoch 208/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 284.2554 - mae: 6.5755\n",
      "Epoch 209/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 290.6795 - mae: 7.5949\n",
      "Epoch 210/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 287.2314 - mae: 7.9258\n",
      "Epoch 211/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.2642 - mae: 7.1053\n",
      "Epoch 212/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 272.2465 - mae: 6.1583\n",
      "Epoch 213/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.7414 - mae: 6.4257\n",
      "Epoch 214/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.9708 - mae: 6.4773\n",
      "Epoch 215/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 287.6425 - mae: 6.8337\n",
      "Epoch 216/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 272.7025 - mae: 6.8210\n",
      "Epoch 217/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 274.8796 - mae: 6.3653\n",
      "Epoch 218/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 272.3033 - mae: 6.2567\n",
      "Epoch 219/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 272.6527 - mae: 6.1885\n",
      "Epoch 220/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 271.0765 - mae: 6.2677\n",
      "Epoch 221/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.9347 - mae: 6.5098\n",
      "Epoch 222/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 272.2047 - mae: 6.3016\n",
      "Epoch 223/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.9618 - mae: 7.2861\n",
      "Epoch 224/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.9143 - mae: 8.7688\n",
      "Epoch 225/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 285.2177 - mae: 8.0592\n",
      "Epoch 226/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.9251 - mae: 6.8858\n",
      "Epoch 227/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.0396 - mae: 6.2295\n",
      "Epoch 228/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.9955 - mae: 7.0755\n",
      "Epoch 229/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.4324 - mae: 6.6595\n",
      "Epoch 230/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.8674 - mae: 7.0889\n",
      "Epoch 231/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.5813 - mae: 6.7574\n",
      "Epoch 232/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.7205 - mae: 7.0644\n",
      "Epoch 233/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.4335 - mae: 6.8703\n",
      "Epoch 234/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.0177 - mae: 6.6932\n",
      "Epoch 235/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 271.2744 - mae: 6.2957\n",
      "Epoch 236/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 271.5214 - mae: 6.0894\n",
      "Epoch 237/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.9432 - mae: 5.9523\n",
      "Epoch 238/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 292.7629 - mae: 7.6859\n",
      "Epoch 239/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 312.6417 - mae: 8.8069\n",
      "Epoch 240/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 301.4141 - mae: 8.5092\n",
      "Epoch 241/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 268.5457 - mae: 6.6562\n",
      "Epoch 242/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.1943 - mae: 6.7792\n",
      "Epoch 243/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 282.3757 - mae: 7.3996\n",
      "Epoch 244/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.0448 - mae: 7.6287\n",
      "Epoch 245/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.7138 - mae: 7.1860\n",
      "Epoch 246/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.3743 - mae: 6.2028\n",
      "Epoch 247/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.9579 - mae: 6.2498\n",
      "Epoch 248/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 275.5092 - mae: 7.0507\n",
      "Epoch 249/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.6575 - mae: 7.2516\n",
      "Epoch 250/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.4660 - mae: 6.3899\n",
      "Epoch 251/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 279.8106 - mae: 7.3539\n",
      "Epoch 252/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 279.7128 - mae: 7.3028\n",
      "Epoch 253/500\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 274.9977 - mae: 6.3639\n",
      "Epoch 254/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.7308 - mae: 6.9430\n",
      "Epoch 255/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 289.2961 - mae: 7.1296\n",
      "Epoch 256/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.9545 - mae: 7.6892\n",
      "Epoch 257/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.5557 - mae: 7.7404\n",
      "Epoch 258/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.2636 - mae: 6.2591\n",
      "Epoch 259/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.1708 - mae: 6.6392\n",
      "Epoch 260/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 273.6701 - mae: 6.8284\n",
      "Epoch 261/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.9463 - mae: 6.6240\n",
      "Epoch 262/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 264.0480 - mae: 6.3117\n",
      "Epoch 263/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.9611 - mae: 6.1851\n",
      "Epoch 264/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.3476 - mae: 6.2446\n",
      "Epoch 265/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.0555 - mae: 6.6717\n",
      "Epoch 266/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.1683 - mae: 6.3585\n",
      "Epoch 267/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.9536 - mae: 6.0829\n",
      "Epoch 268/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 281.3721 - mae: 6.6348\n",
      "Epoch 269/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 290.7918 - mae: 7.9825\n",
      "Epoch 270/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.0273 - mae: 7.4709\n",
      "Epoch 271/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.9038 - mae: 7.1900\n",
      "Epoch 272/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 284.6436 - mae: 7.4888\n",
      "Epoch 273/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 271.6188 - mae: 6.2234\n",
      "Epoch 274/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 272.8539 - mae: 6.5466\n",
      "Epoch 275/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 271.1244 - mae: 6.6816\n",
      "Epoch 276/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 268.2371 - mae: 6.2228\n",
      "Epoch 277/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.2295 - mae: 6.2139\n",
      "Epoch 278/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.4941 - mae: 6.1580\n",
      "Epoch 279/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 270.5992 - mae: 6.0437\n",
      "Epoch 280/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 291.5851 - mae: 7.3888\n",
      "Epoch 281/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 283.7703 - mae: 8.2704\n",
      "Epoch 282/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.3862 - mae: 7.7516\n",
      "Epoch 283/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.3004 - mae: 6.5192\n",
      "Epoch 284/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 264.1140 - mae: 6.2038\n",
      "Epoch 285/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 265.8537 - mae: 6.2886\n",
      "Epoch 286/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 281.9992 - mae: 6.7277\n",
      "Epoch 287/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 288.2009 - mae: 7.6325\n",
      "Epoch 288/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 262.4822 - mae: 6.2791\n",
      "Epoch 289/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.5916 - mae: 6.5090\n",
      "Epoch 290/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 288.6018 - mae: 7.1941\n",
      "Epoch 291/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 289.1180 - mae: 8.1324\n",
      "Epoch 292/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 284.1273 - mae: 8.1417\n",
      "Epoch 293/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 265.2980 - mae: 6.4506\n",
      "Epoch 294/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 265.5796 - mae: 6.4029\n",
      "Epoch 295/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 269.4634 - mae: 6.3961\n",
      "Epoch 296/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 268.8711 - mae: 6.8804\n",
      "Epoch 297/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.7580 - mae: 6.9013\n",
      "Epoch 298/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 270.1227 - mae: 7.2722\n",
      "Epoch 299/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.4222 - mae: 7.2623\n",
      "Epoch 300/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 263.8501 - mae: 6.6819\n",
      "Epoch 301/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 265.3247 - mae: 6.4884\n",
      "Epoch 302/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.2224 - mae: 6.0659\n",
      "Epoch 303/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 260.3785 - mae: 5.8668\n",
      "Epoch 304/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 260.3038 - mae: 5.9665\n",
      "Epoch 305/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 269.1166 - mae: 6.2437\n",
      "Epoch 306/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 284.8748 - mae: 7.4194\n",
      "Epoch 307/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 273.0229 - mae: 7.8890\n",
      "Epoch 308/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.2841 - mae: 6.9605\n",
      "Epoch 309/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 269.9980 - mae: 6.5630\n",
      "Epoch 310/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.3041 - mae: 6.7609\n",
      "Epoch 311/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 263.2456 - mae: 6.6071\n",
      "Epoch 312/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 271.7744 - mae: 6.1150\n",
      "Epoch 313/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 265.3298 - mae: 6.5733\n",
      "Epoch 314/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 263.2317 - mae: 6.6199\n",
      "Epoch 315/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 268.0110 - mae: 6.3522\n",
      "Epoch 316/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.8081 - mae: 6.4214\n",
      "Epoch 317/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.4568 - mae: 6.8467\n",
      "Epoch 318/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 269.7212 - mae: 7.4083\n",
      "Epoch 319/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 268.9143 - mae: 7.5720\n",
      "Epoch 320/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 268.8003 - mae: 7.0222\n",
      "Epoch 321/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.5159 - mae: 6.1421\n",
      "Epoch 322/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 264.1323 - mae: 6.0370\n",
      "Epoch 323/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 261.5708 - mae: 6.2546\n",
      "Epoch 324/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.6379 - mae: 6.3704\n",
      "Epoch 325/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 261.8384 - mae: 6.6372\n",
      "Epoch 326/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 261.3467 - mae: 6.3810\n",
      "Epoch 327/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.4347 - mae: 6.6818\n",
      "Epoch 328/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.2853 - mae: 8.3050\n",
      "Epoch 329/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.7067 - mae: 8.8807\n",
      "Epoch 330/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.9948 - mae: 8.5931\n",
      "Epoch 331/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 283.3229 - mae: 7.5078\n",
      "Epoch 332/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.5604 - mae: 6.6790\n",
      "Epoch 333/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 258.5002 - mae: 6.3090\n",
      "Epoch 334/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 260.3043 - mae: 6.2064\n",
      "Epoch 335/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 256.4683 - mae: 6.0300\n",
      "Epoch 336/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 261.2924 - mae: 6.2221\n",
      "Epoch 337/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 262.7331 - mae: 6.4130\n",
      "Epoch 338/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.3228 - mae: 6.2817\n",
      "Epoch 339/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.4858 - mae: 6.2187\n",
      "Epoch 340/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 255.1476 - mae: 5.9448\n",
      "Epoch 341/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 263.3559 - mae: 6.2595\n",
      "Epoch 342/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 253.7094 - mae: 6.2052\n",
      "Epoch 343/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 258.3755 - mae: 6.3731\n",
      "Epoch 344/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.1757 - mae: 5.9101\n",
      "Epoch 345/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 255.8944 - mae: 6.0567\n",
      "Epoch 346/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 281.5418 - mae: 6.8689\n",
      "Epoch 347/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.5135 - mae: 8.7530\n",
      "Epoch 348/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 263.5253 - mae: 7.4663\n",
      "Epoch 349/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 257.0748 - mae: 6.4335\n",
      "Epoch 350/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 254.3688 - mae: 6.1647\n",
      "Epoch 351/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 260.5438 - mae: 6.0559\n",
      "Epoch 352/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 264.4481 - mae: 6.4260\n",
      "Epoch 353/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.9064 - mae: 6.1321\n",
      "Epoch 354/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 259.0780 - mae: 6.0013\n",
      "Epoch 355/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 253.1634 - mae: 6.4849\n",
      "Epoch 356/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 256.9637 - mae: 6.2604\n",
      "Epoch 357/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 258.8652 - mae: 6.1257\n",
      "Epoch 358/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 250.7034 - mae: 6.0963\n",
      "Epoch 359/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.1537 - mae: 6.0864\n",
      "Epoch 360/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.5681 - mae: 6.1712\n",
      "Epoch 361/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.1506 - mae: 7.2977\n",
      "Epoch 362/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.8924 - mae: 8.1793\n",
      "Epoch 363/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 256.9812 - mae: 7.5760\n",
      "Epoch 364/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 251.7457 - mae: 6.3874\n",
      "Epoch 365/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 251.2210 - mae: 5.9906\n",
      "Epoch 366/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 252.6452 - mae: 6.2580\n",
      "Epoch 367/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 248.2592 - mae: 6.3910\n",
      "Epoch 368/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 261.7072 - mae: 6.7602\n",
      "Epoch 369/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 269.4309 - mae: 8.0734\n",
      "Epoch 370/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 271.4349 - mae: 8.4880\n",
      "Epoch 371/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 259.7836 - mae: 7.8809\n",
      "Epoch 372/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 249.2000 - mae: 7.0490\n",
      "Epoch 373/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 261.7488 - mae: 7.0895\n",
      "Epoch 374/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 262.6278 - mae: 6.5516\n",
      "Epoch 375/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 249.2244 - mae: 6.3522\n",
      "Epoch 376/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 249.0697 - mae: 6.5691\n",
      "Epoch 377/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 244.6961 - mae: 5.9201\n",
      "Epoch 378/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 244.4737 - mae: 5.7550\n",
      "Epoch 379/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 246.4851 - mae: 5.7547\n",
      "Epoch 380/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 258.7215 - mae: 6.6720\n",
      "Epoch 381/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 251.8104 - mae: 6.4013\n",
      "Epoch 382/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 252.6830 - mae: 6.6466\n",
      "Epoch 383/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 244.3829 - mae: 6.2686\n",
      "Epoch 384/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.6305 - mae: 6.1684\n",
      "Epoch 385/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 239.9104 - mae: 6.1415\n",
      "Epoch 386/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 251.1293 - mae: 6.5419\n",
      "Epoch 387/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 242.3329 - mae: 6.4653\n",
      "Epoch 388/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 242.1605 - mae: 5.7648\n",
      "Epoch 389/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 239.4344 - mae: 5.9362\n",
      "Epoch 390/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 243.1617 - mae: 5.9503\n",
      "Epoch 391/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 248.3455 - mae: 6.4481\n",
      "Epoch 392/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 248.6421 - mae: 6.5317\n",
      "Epoch 393/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 270.2896 - mae: 7.4021\n",
      "Epoch 394/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.0909 - mae: 6.7153\n",
      "Epoch 395/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 252.2091 - mae: 7.0426\n",
      "Epoch 396/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 241.1967 - mae: 6.1449\n",
      "Epoch 397/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.4795 - mae: 6.1878\n",
      "Epoch 398/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 264.3789 - mae: 7.5739\n",
      "Epoch 399/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 254.6131 - mae: 6.9641\n",
      "Epoch 400/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 245.0256 - mae: 6.3127\n",
      "Epoch 401/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 241.3065 - mae: 5.7264\n",
      "Epoch 402/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.8813 - mae: 6.1777\n",
      "Epoch 403/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 237.7084 - mae: 5.7200\n",
      "Epoch 404/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 235.8141 - mae: 5.6664\n",
      "Epoch 405/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 235.5217 - mae: 5.8400\n",
      "Epoch 406/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 234.5421 - mae: 5.8834\n",
      "Epoch 407/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.8020 - mae: 6.3172\n",
      "Epoch 408/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 235.1724 - mae: 6.1213\n",
      "Epoch 409/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 234.2306 - mae: 5.8671\n",
      "Epoch 410/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 238.0583 - mae: 6.3379\n",
      "Epoch 411/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.8001 - mae: 7.1304\n",
      "Epoch 412/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 237.8369 - mae: 6.4772\n",
      "Epoch 413/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.0006 - mae: 6.0360\n",
      "Epoch 414/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 234.4564 - mae: 5.9827\n",
      "Epoch 415/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 233.4845 - mae: 6.1785\n",
      "Epoch 416/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.6827 - mae: 6.8439\n",
      "Epoch 417/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 252.2434 - mae: 7.9405\n",
      "Epoch 418/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 244.1825 - mae: 6.9648\n",
      "Epoch 419/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 240.9363 - mae: 6.3241\n",
      "Epoch 420/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.5617 - mae: 6.7649\n",
      "Epoch 421/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 239.4327 - mae: 6.9645\n",
      "Epoch 422/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 238.8135 - mae: 6.9216\n",
      "Epoch 423/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 236.4948 - mae: 6.8935\n",
      "Epoch 424/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 233.4037 - mae: 5.9028\n",
      "Epoch 425/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.7510 - mae: 5.7439\n",
      "Epoch 426/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.1273 - mae: 5.9351\n",
      "Epoch 427/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 230.8108 - mae: 6.3312\n",
      "Epoch 428/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 229.5119 - mae: 6.0115\n",
      "Epoch 429/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 227.6378 - mae: 5.6403\n",
      "Epoch 430/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.5915 - mae: 5.9175\n",
      "Epoch 431/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 235.9707 - mae: 6.5278\n",
      "Epoch 432/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 228.0766 - mae: 6.0961\n",
      "Epoch 433/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 235.7062 - mae: 5.8099\n",
      "Epoch 434/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 232.3753 - mae: 5.9893\n",
      "Epoch 435/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 231.1454 - mae: 6.5050\n",
      "Epoch 436/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.8602 - mae: 6.6970\n",
      "Epoch 437/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 230.9844 - mae: 5.6744\n",
      "Epoch 438/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 225.0215 - mae: 5.7447\n",
      "Epoch 439/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 224.7499 - mae: 5.7257\n",
      "Epoch 440/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.6564 - mae: 5.9699\n",
      "Epoch 441/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 226.9471 - mae: 6.0873\n",
      "Epoch 442/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 225.5559 - mae: 5.8713\n",
      "Epoch 443/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 228.6738 - mae: 6.2859\n",
      "Epoch 444/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 224.2789 - mae: 5.9696\n",
      "Epoch 445/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.2671 - mae: 6.3041\n",
      "Epoch 446/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 231.7226 - mae: 6.0722\n",
      "Epoch 447/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 230.1799 - mae: 6.0385\n",
      "Epoch 448/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 226.8764 - mae: 6.6084\n",
      "Epoch 449/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.4131 - mae: 6.7517\n",
      "Epoch 450/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 228.1121 - mae: 6.5260\n",
      "Epoch 451/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 232.7452 - mae: 6.0703\n",
      "Epoch 452/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.1202 - mae: 5.6159\n",
      "Epoch 453/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.6552 - mae: 6.6577\n",
      "Epoch 454/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 225.7232 - mae: 6.5785\n",
      "Epoch 455/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.9487 - mae: 6.7358\n",
      "Epoch 456/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 227.3692 - mae: 6.8653\n",
      "Epoch 457/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.9499 - mae: 6.2596\n",
      "Epoch 458/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.3679 - mae: 6.2200\n",
      "Epoch 459/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.5985 - mae: 6.1585\n",
      "Epoch 460/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.5006 - mae: 7.1566\n",
      "Epoch 461/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.6037 - mae: 6.0042\n",
      "Epoch 462/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.5966 - mae: 6.0707\n",
      "Epoch 463/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.8018 - mae: 7.0290\n",
      "Epoch 464/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 225.2748 - mae: 6.9112\n",
      "Epoch 465/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.9876 - mae: 5.7722\n",
      "Epoch 466/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.6492 - mae: 6.4315\n",
      "Epoch 467/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 225.3571 - mae: 6.0056\n",
      "Epoch 468/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 216.1378 - mae: 5.9706\n",
      "Epoch 469/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 217.7234 - mae: 5.5339\n",
      "Epoch 470/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 242.2311 - mae: 7.3267\n",
      "Epoch 471/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 236.3474 - mae: 8.1965\n",
      "Epoch 472/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.0616 - mae: 6.1668\n",
      "Epoch 473/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.1967 - mae: 6.3781\n",
      "Epoch 474/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 236.2994 - mae: 7.7229\n",
      "Epoch 475/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 230.8972 - mae: 6.8136\n",
      "Epoch 476/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.0612 - mae: 6.6747\n",
      "Epoch 477/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 219.0851 - mae: 5.6785\n",
      "Epoch 478/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.6047 - mae: 5.7982\n",
      "Epoch 479/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 215.5522 - mae: 5.8203\n",
      "Epoch 480/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.7536 - mae: 5.5298\n",
      "Epoch 481/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.6756 - mae: 5.7328\n",
      "Epoch 482/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.0909 - mae: 5.9597\n",
      "Epoch 483/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 239.8986 - mae: 8.1235\n",
      "Epoch 484/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 218.6213 - mae: 6.5952\n",
      "Epoch 485/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 230.4135 - mae: 6.6228\n",
      "Epoch 486/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 221.2421 - mae: 6.3059\n",
      "Epoch 487/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 212.8361 - mae: 5.4023\n",
      "Epoch 488/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.1680 - mae: 5.5618\n",
      "Epoch 489/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 206.4643 - mae: 5.8690\n",
      "Epoch 490/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 213.0999 - mae: 5.6386\n",
      "Epoch 491/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.5979 - mae: 5.4445\n",
      "Epoch 492/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 213.5868 - mae: 5.9112\n",
      "Epoch 493/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 216.6894 - mae: 6.9770\n",
      "Epoch 494/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 210.8419 - mae: 6.6310\n",
      "Epoch 495/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 207.2106 - mae: 6.0198\n",
      "Epoch 496/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 203.6909 - mae: 5.7861\n",
      "Epoch 497/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 215.3127 - mae: 6.4200\n",
      "Epoch 498/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 209.0189 - mae: 6.1034\n",
      "Epoch 499/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 209.8871 - mae: 5.5722\n",
      "Epoch 500/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 211.3542 - mae: 6.5551\n",
      "Best: 0.962026 using {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.958660 (0.011620) with: {'activation_func': 'relu', 'first_layer_nodes': 100, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.955952 (0.008398) with: {'activation_func': 'relu', 'first_layer_nodes': 100, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.953172 (0.009661) with: {'activation_func': 'relu', 'first_layer_nodes': 100, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.959197 (0.011510) with: {'activation_func': 'relu', 'first_layer_nodes': 150, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.955458 (0.011814) with: {'activation_func': 'relu', 'first_layer_nodes': 150, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.957935 (0.004180) with: {'activation_func': 'relu', 'first_layer_nodes': 150, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.959138 (0.012639) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.962026 (0.014930) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.958244 (0.014918) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.948489 (0.011878) with: {'activation_func': 'softplus', 'first_layer_nodes': 100, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.951462 (0.010737) with: {'activation_func': 'softplus', 'first_layer_nodes': 100, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.945257 (0.019174) with: {'activation_func': 'softplus', 'first_layer_nodes': 100, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.952665 (0.010515) with: {'activation_func': 'softplus', 'first_layer_nodes': 150, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.950266 (0.014805) with: {'activation_func': 'softplus', 'first_layer_nodes': 150, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.953016 (0.010688) with: {'activation_func': 'softplus', 'first_layer_nodes': 150, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.953803 (0.010814) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.953546 (0.009606) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.950764 (0.011118) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.947498 (0.007925) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 100, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.942494 (0.007032) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 100, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.948362 (0.010731) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 100, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.951761 (0.006971) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 150, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.948011 (0.007032) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 150, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.954967 (0.004245) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 150, 'last_layer_nodes': 75, 'n_layers': 3}\n",
      "0.950649 (0.008897) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 25, 'n_layers': 3}\n",
      "0.953904 (0.007083) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.949154 (0.013826) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 75, 'n_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "activation_funcs = ['relu', 'softplus', 'leaky_relu'] \n",
    "param_grid = dict(n_layers=[3], first_layer_nodes = [100, 150, 200], last_layer_nodes = [25,50, 75],  activation_func = activation_funcs)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid,n_jobs=-1, cv=3, scoring = 'r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch, optimizer, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=125, activation='relu'))\n",
    " model.add(Dense(units=50, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " # Compile model\n",
    " model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.997690 using {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.981684 (0.013850) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.980409 (0.008379) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.988579 (0.009050) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.977251 (0.008355) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.966591 (0.014867) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.975728 (0.009301) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.971950 (0.009815) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.966126 (0.010468) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.969748 (0.010311) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.984280 (0.008493) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.974883 (0.008336) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.980677 (0.009286) with: {'batch_size': 20, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.980968 (0.019464) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.992492 (0.008708) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.995081 (0.002983) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.984016 (0.008017) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.982167 (0.007298) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.984319 (0.002826) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.975263 (0.010598) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.977290 (0.008038) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.977551 (0.006752) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.994575 (0.005179) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.991261 (0.004354) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.989752 (0.006911) with: {'batch_size': 20, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.992540 (0.004628) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.995313 (0.003087) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.997243 (0.001279) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.986700 (0.009021) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.992894 (0.006155) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.993938 (0.004439) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.983707 (0.007668) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.980917 (0.007374) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.976955 (0.010345) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.997690 (0.001658) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.996521 (0.001443) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.997013 (0.003095) with: {'batch_size': 20, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.962840 (0.012981) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.982279 (0.009390) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.970115 (0.007311) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.971943 (0.008698) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.970217 (0.012100) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.969051 (0.010914) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.964631 (0.011126) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.960880 (0.012909) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.962982 (0.012018) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.966137 (0.017803) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.975009 (0.006762) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.981627 (0.010556) with: {'batch_size': 30, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.979405 (0.018430) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.987031 (0.010619) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.988742 (0.003382) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.973248 (0.010526) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.977286 (0.011438) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.978497 (0.008219) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.972613 (0.007422) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.969123 (0.012604) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.968938 (0.006987) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.984381 (0.007570) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.981945 (0.010959) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.982106 (0.011478) with: {'batch_size': 30, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.994891 (0.002360) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.990673 (0.001121) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.986933 (0.010108) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.982281 (0.007671) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.987099 (0.006705) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.983598 (0.010507) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.977847 (0.006825) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.974485 (0.009560) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.975017 (0.008906) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.989684 (0.008969) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.990185 (0.007438) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.990900 (0.004185) with: {'batch_size': 30, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.945567 (0.025665) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.886243 (0.059508) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.966825 (0.008130) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.965075 (0.005926) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.964435 (0.007895) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.940747 (0.034991) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.938780 (0.024162) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.945200 (0.010769) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.938697 (0.016149) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.953981 (0.024462) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.954231 (0.022957) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.962768 (0.013596) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.955314 (0.021771) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.977810 (0.008081) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.951673 (0.026292) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.967483 (0.011899) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.954934 (0.022999) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.965249 (0.016100) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.950800 (0.011882) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.950711 (0.010149) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.953692 (0.009306) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.950829 (0.041232) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.974849 (0.009818) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.971128 (0.010596) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.975846 (0.005077) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.945958 (0.055872) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.923124 (0.036695) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.967077 (0.010859) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.973171 (0.009590) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.974942 (0.008054) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.959937 (0.010783) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.958987 (0.011357) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.958304 (0.011285) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.970688 (0.016356) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.957856 (0.034438) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.972254 (0.015203) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [20, 30,50]\n",
    "epochs = [300, 400, 500]\n",
    "optimizer = ['RMSprop', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, model__optimizer=optimizer, optimizer__learning_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, scoring = 'r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
