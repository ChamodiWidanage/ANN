{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_type        546 non-null    object \n",
      " 1   Charge_size        546 non-null    float64\n",
      " 2   Standoff_distance  546 non-null    float64\n",
      " 3   Impulse            546 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('IDataset1.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_size        546 non-null    float64\n",
      " 1   Standoff_distance  546 non-null    float64\n",
      " 2   Impulse            546 non-null    float64\n",
      " 3   Charge_type_CompB  546 non-null    uint8  \n",
      " 4   Charge_type_TNT    546 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 14.0 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Charge_type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 4) (546,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset['Impulse']\n",
    "X = dataset.drop('Impulse', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - layers, neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor as KR\n",
    "import math\n",
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chathura Gamage\\AppData\\Local\\Temp\\ipykernel_11276\\2480470563.py:18: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KR(build_fn=create_model, epochs = 500, batch_size = 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_model(n_layers, first_layer_nodes, last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(units = first_layer_nodes,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer = opt, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model = KR(build_fn=create_model, epochs = 500, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 20027.7910 - mae: 107.2213\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 17631.3320 - mae: 96.0027\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 14630.6572 - mae: 81.1953\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 11737.0107 - mae: 68.8479\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9378.6211 - mae: 65.9665\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8320.0547 - mae: 67.2057\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7636.6987 - mae: 65.2384\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6728.8101 - mae: 58.7065\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6059.8887 - mae: 53.0291\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5422.9336 - mae: 49.5991\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 4912.3467 - mae: 47.8811\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 4336.7036 - mae: 45.9097\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 3944.9917 - mae: 44.7238\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 3584.5107 - mae: 43.3848\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 3312.9346 - mae: 42.1477\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 3046.2097 - mae: 40.4012\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2822.4597 - mae: 38.3482\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2659.2961 - mae: 36.5509\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2446.4836 - mae: 34.6164\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2286.0859 - mae: 32.8255\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2123.9929 - mae: 31.2762\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1985.0297 - mae: 29.8652\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1869.2122 - mae: 28.8316\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1768.7572 - mae: 27.8299\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1671.9790 - mae: 27.4650\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1557.2487 - mae: 25.8644\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1473.4568 - mae: 25.0061\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1401.9150 - mae: 24.3347\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1306.1780 - mae: 23.6665\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1218.1785 - mae: 22.5212\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1133.8025 - mae: 21.4443\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1062.8584 - mae: 20.7172\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 992.8029 - mae: 19.7301\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 927.5329 - mae: 19.0079\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 863.3401 - mae: 18.0524\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 813.8031 - mae: 17.2670\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 777.3207 - mae: 16.5824\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 778.7515 - mae: 17.0965\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 721.1245 - mae: 17.0531\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 675.5758 - mae: 15.4761\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 635.7308 - mae: 14.6306\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 608.3967 - mae: 14.2769\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 591.4515 - mae: 14.0591\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 568.8627 - mae: 13.3993\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 574.2710 - mae: 13.7068\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 552.6036 - mae: 13.2545\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 542.9921 - mae: 12.9554\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 521.3070 - mae: 12.5290\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 502.6840 - mae: 12.4185\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 509.1957 - mae: 11.8175\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 505.1638 - mae: 12.4869\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 466.2440 - mae: 11.5762\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 461.1518 - mae: 11.2946\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 474.4575 - mae: 11.3902\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 453.2131 - mae: 12.2000\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 436.1756 - mae: 10.7138\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 433.4690 - mae: 10.7408\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 424.4577 - mae: 10.3692\n",
      "Epoch 59/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 409.6365 - mae: 9.8984\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 406.8458 - mae: 9.5392\n",
      "Epoch 61/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 394.1922 - mae: 9.7374\n",
      "Epoch 62/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 391.7828 - mae: 9.0424\n",
      "Epoch 63/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 392.8816 - mae: 9.0804\n",
      "Epoch 64/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 384.2560 - mae: 8.9793\n",
      "Epoch 65/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 380.6726 - mae: 9.1080\n",
      "Epoch 66/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.3843 - mae: 9.0045\n",
      "Epoch 67/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.6395 - mae: 9.0683\n",
      "Epoch 68/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 375.9102 - mae: 8.6019\n",
      "Epoch 69/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 397.5886 - mae: 10.2650\n",
      "Epoch 70/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 420.9004 - mae: 12.2631\n",
      "Epoch 71/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 391.1763 - mae: 10.9999\n",
      "Epoch 72/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 372.6486 - mae: 9.5461\n",
      "Epoch 73/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 352.7249 - mae: 8.9187\n",
      "Epoch 74/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 347.7330 - mae: 8.3886\n",
      "Epoch 75/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 352.2766 - mae: 8.5642\n",
      "Epoch 76/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 345.1465 - mae: 8.4751\n",
      "Epoch 77/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 342.2647 - mae: 8.8530\n",
      "Epoch 78/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 336.3466 - mae: 7.9494\n",
      "Epoch 79/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 343.4411 - mae: 8.3614\n",
      "Epoch 80/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 334.1446 - mae: 7.9784\n",
      "Epoch 81/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 335.4317 - mae: 8.0790\n",
      "Epoch 82/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 330.2826 - mae: 7.7068\n",
      "Epoch 83/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 327.7092 - mae: 8.0979\n",
      "Epoch 84/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 335.0121 - mae: 8.5421\n",
      "Epoch 85/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 333.1431 - mae: 8.7286\n",
      "Epoch 86/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 353.1953 - mae: 9.4669\n",
      "Epoch 87/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 355.9293 - mae: 9.0769\n",
      "Epoch 88/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 338.9796 - mae: 8.5461\n",
      "Epoch 89/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 366.2699 - mae: 9.8327\n",
      "Epoch 90/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 337.2257 - mae: 8.9553\n",
      "Epoch 91/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 322.9435 - mae: 7.5375\n",
      "Epoch 92/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 319.5088 - mae: 7.7242\n",
      "Epoch 93/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 321.7809 - mae: 7.7909\n",
      "Epoch 94/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 324.0536 - mae: 7.6906\n",
      "Epoch 95/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 326.4609 - mae: 7.7012\n",
      "Epoch 96/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 337.5967 - mae: 8.7153\n",
      "Epoch 97/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 324.0958 - mae: 8.6869\n",
      "Epoch 98/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 326.3579 - mae: 7.8943\n",
      "Epoch 99/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 311.5092 - mae: 7.0427\n",
      "Epoch 100/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 314.3704 - mae: 7.3594\n",
      "Epoch 101/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 319.1593 - mae: 8.0399\n",
      "Epoch 102/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 320.7474 - mae: 7.0024\n",
      "Epoch 103/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 315.7096 - mae: 7.6928\n",
      "Epoch 104/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 327.9693 - mae: 8.5098\n",
      "Epoch 105/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 329.2524 - mae: 7.5883\n",
      "Epoch 106/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 319.1989 - mae: 8.2004\n",
      "Epoch 107/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 342.1018 - mae: 9.8705\n",
      "Epoch 108/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 321.6145 - mae: 8.9216\n",
      "Epoch 109/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 338.5858 - mae: 9.3362\n",
      "Epoch 110/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 313.1200 - mae: 8.1948\n",
      "Epoch 111/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 308.4628 - mae: 7.3645\n",
      "Epoch 112/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 304.9075 - mae: 7.2058\n",
      "Epoch 113/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 312.0788 - mae: 7.3665\n",
      "Epoch 114/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 323.6714 - mae: 8.5640\n",
      "Epoch 115/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 351.0211 - mae: 9.9308\n",
      "Epoch 116/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 342.7367 - mae: 9.1189\n",
      "Epoch 117/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 334.8603 - mae: 8.1880\n",
      "Epoch 118/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 319.9732 - mae: 8.2827\n",
      "Epoch 119/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 326.1819 - mae: 8.9690\n",
      "Epoch 120/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 312.5406 - mae: 7.3733\n",
      "Epoch 121/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 304.4946 - mae: 7.1230\n",
      "Epoch 122/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 305.7139 - mae: 8.0451\n",
      "Epoch 123/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 322.6281 - mae: 8.4757\n",
      "Epoch 124/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 313.4975 - mae: 8.6458\n",
      "Epoch 125/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 312.7397 - mae: 8.2811\n",
      "Epoch 126/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 317.3561 - mae: 8.2510\n",
      "Epoch 127/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 314.1226 - mae: 7.4654\n",
      "Epoch 128/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 320.5813 - mae: 7.7414\n",
      "Epoch 129/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 296.9830 - mae: 7.1528\n",
      "Epoch 130/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 297.3359 - mae: 7.3355\n",
      "Epoch 131/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 301.9857 - mae: 7.3008\n",
      "Epoch 132/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 308.2671 - mae: 7.6139\n",
      "Epoch 133/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 310.2253 - mae: 8.0703\n",
      "Epoch 134/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 298.8672 - mae: 7.1722\n",
      "Epoch 135/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 307.2514 - mae: 7.1856\n",
      "Epoch 136/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 304.3991 - mae: 7.8598\n",
      "Epoch 137/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 317.7156 - mae: 7.6266\n",
      "Epoch 138/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 312.3921 - mae: 7.3897\n",
      "Epoch 139/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 325.0290 - mae: 8.6919\n",
      "Epoch 140/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 305.1779 - mae: 8.2230\n",
      "Epoch 141/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 304.9469 - mae: 8.2758\n",
      "Epoch 142/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 317.1602 - mae: 8.3105\n",
      "Epoch 143/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 299.8228 - mae: 7.2460\n",
      "Epoch 144/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 296.0955 - mae: 6.6408\n",
      "Epoch 145/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.8238 - mae: 7.7907\n",
      "Epoch 146/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 298.5258 - mae: 7.6375\n",
      "Epoch 147/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.1278 - mae: 7.5226\n",
      "Epoch 148/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.3420 - mae: 6.5468\n",
      "Epoch 149/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 302.3084 - mae: 7.3228\n",
      "Epoch 150/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 296.5334 - mae: 6.9706\n",
      "Epoch 151/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.3118 - mae: 7.1150\n",
      "Epoch 152/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 291.0645 - mae: 6.6225\n",
      "Epoch 153/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.4630 - mae: 6.8406\n",
      "Epoch 154/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 299.7407 - mae: 7.1382\n",
      "Epoch 155/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 292.8148 - mae: 7.0739\n",
      "Epoch 156/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 297.6079 - mae: 7.1501\n",
      "Epoch 157/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 291.3388 - mae: 6.6700\n",
      "Epoch 158/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 298.5511 - mae: 7.0652\n",
      "Epoch 159/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 307.4641 - mae: 7.2395\n",
      "Epoch 160/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 289.6726 - mae: 6.6957\n",
      "Epoch 161/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 289.9865 - mae: 6.5341\n",
      "Epoch 162/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 293.7771 - mae: 6.7325\n",
      "Epoch 163/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.3026 - mae: 7.7477\n",
      "Epoch 164/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 288.3329 - mae: 6.8497\n",
      "Epoch 165/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 309.0733 - mae: 7.3634\n",
      "Epoch 166/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 291.4073 - mae: 7.8816\n",
      "Epoch 167/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 299.1888 - mae: 8.3495\n",
      "Epoch 168/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 308.5858 - mae: 8.6485\n",
      "Epoch 169/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.2792 - mae: 7.6935\n",
      "Epoch 170/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.3580 - mae: 8.0930\n",
      "Epoch 171/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 302.2397 - mae: 8.0106\n",
      "Epoch 172/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 293.6551 - mae: 6.6356\n",
      "Epoch 173/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 285.4845 - mae: 6.5958\n",
      "Epoch 174/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 283.8064 - mae: 6.7796\n",
      "Epoch 175/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 291.3393 - mae: 6.6949\n",
      "Epoch 176/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 283.7965 - mae: 6.4264\n",
      "Epoch 177/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.9404 - mae: 6.5971\n",
      "Epoch 178/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 290.1451 - mae: 6.3644\n",
      "Epoch 179/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.7124 - mae: 6.3658\n",
      "Epoch 180/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 283.8156 - mae: 6.3850\n",
      "Epoch 181/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 286.7551 - mae: 6.7435\n",
      "Epoch 182/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 284.7688 - mae: 6.7351\n",
      "Epoch 183/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.9677 - mae: 6.8513\n",
      "Epoch 184/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.3645 - mae: 8.4242\n",
      "Epoch 185/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.0472 - mae: 6.9288\n",
      "Epoch 186/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.9860 - mae: 6.5767\n",
      "Epoch 187/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.4424 - mae: 7.3872\n",
      "Epoch 188/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.7311 - mae: 6.3952\n",
      "Epoch 189/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.6468 - mae: 6.5495\n",
      "Epoch 190/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.4946 - mae: 6.6414\n",
      "Epoch 191/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 283.6324 - mae: 6.5039\n",
      "Epoch 192/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 286.3689 - mae: 7.0456\n",
      "Epoch 193/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 291.3060 - mae: 7.7440\n",
      "Epoch 194/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 275.1080 - mae: 6.4933\n",
      "Epoch 195/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 282.9411 - mae: 6.5265\n",
      "Epoch 196/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 281.3231 - mae: 6.5288\n",
      "Epoch 197/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.3524 - mae: 6.5858\n",
      "Epoch 198/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.5782 - mae: 6.4592\n",
      "Epoch 199/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 274.3525 - mae: 6.4499\n",
      "Epoch 200/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.7879 - mae: 6.9483\n",
      "Epoch 201/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.0498 - mae: 6.4856\n",
      "Epoch 202/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.6758 - mae: 6.3546\n",
      "Epoch 203/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.9279 - mae: 6.4238\n",
      "Epoch 204/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.8452 - mae: 6.4072\n",
      "Epoch 205/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 303.3080 - mae: 8.3946\n",
      "Epoch 206/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.4001 - mae: 8.6996\n",
      "Epoch 207/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 279.9967 - mae: 7.1510\n",
      "Epoch 208/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.6010 - mae: 6.1538\n",
      "Epoch 209/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.6890 - mae: 7.8693\n",
      "Epoch 210/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 347.7044 - mae: 10.8238\n",
      "Epoch 211/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.7980 - mae: 9.4404\n",
      "Epoch 212/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 294.0426 - mae: 7.4027\n",
      "Epoch 213/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 276.3707 - mae: 6.2586\n",
      "Epoch 214/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 277.9243 - mae: 6.9702\n",
      "Epoch 215/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 271.3038 - mae: 6.7109\n",
      "Epoch 216/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 276.2622 - mae: 6.3702\n",
      "Epoch 217/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.5834 - mae: 7.2646\n",
      "Epoch 218/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.1230 - mae: 6.4598\n",
      "Epoch 219/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 272.9442 - mae: 6.0966\n",
      "Epoch 220/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.0792 - mae: 6.0870\n",
      "Epoch 221/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.4353 - mae: 6.2220\n",
      "Epoch 222/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.7963 - mae: 6.1651\n",
      "Epoch 223/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 280.3752 - mae: 7.2025\n",
      "Epoch 224/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.8756 - mae: 7.6956\n",
      "Epoch 225/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.2635 - mae: 9.0474\n",
      "Epoch 226/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 281.3459 - mae: 7.8810\n",
      "Epoch 227/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.2337 - mae: 7.4292\n",
      "Epoch 228/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 275.2071 - mae: 6.8280\n",
      "Epoch 229/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 272.2536 - mae: 6.4982\n",
      "Epoch 230/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 278.9904 - mae: 7.3950\n",
      "Epoch 231/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.1422 - mae: 6.9439\n",
      "Epoch 232/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 270.8726 - mae: 6.2579\n",
      "Epoch 233/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.3116 - mae: 6.4592\n",
      "Epoch 234/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 265.0733 - mae: 6.3260\n",
      "Epoch 235/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.5053 - mae: 6.7835\n",
      "Epoch 236/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 299.4501 - mae: 8.7101\n",
      "Epoch 237/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 300.3073 - mae: 8.8161\n",
      "Epoch 238/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 299.7901 - mae: 7.6630\n",
      "Epoch 239/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.9030 - mae: 6.7378\n",
      "Epoch 240/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 272.1531 - mae: 6.2442\n",
      "Epoch 241/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 264.8270 - mae: 6.6044\n",
      "Epoch 242/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 276.8661 - mae: 7.1376\n",
      "Epoch 243/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 259.7774 - mae: 6.1679\n",
      "Epoch 244/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 273.1436 - mae: 6.5784\n",
      "Epoch 245/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 270.2911 - mae: 6.6446\n",
      "Epoch 246/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 258.8020 - mae: 5.9823\n",
      "Epoch 247/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 258.9329 - mae: 5.7449\n",
      "Epoch 248/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 265.3495 - mae: 6.6592\n",
      "Epoch 249/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 269.2041 - mae: 6.9980\n",
      "Epoch 250/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.5904 - mae: 7.4438\n",
      "Epoch 251/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.7601 - mae: 6.7830\n",
      "Epoch 252/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 267.4325 - mae: 6.9039\n",
      "Epoch 253/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 256.2372 - mae: 6.0076\n",
      "Epoch 254/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 264.1137 - mae: 6.4345\n",
      "Epoch 255/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 266.2938 - mae: 6.8595\n",
      "Epoch 256/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.4192 - mae: 7.3962\n",
      "Epoch 257/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.3802 - mae: 7.4142\n",
      "Epoch 258/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 257.2375 - mae: 6.8941\n",
      "Epoch 259/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.2932 - mae: 6.5114\n",
      "Epoch 260/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 256.1457 - mae: 6.1139\n",
      "Epoch 261/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.7329 - mae: 5.8748\n",
      "Epoch 262/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 255.9465 - mae: 6.5702\n",
      "Epoch 263/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 251.6011 - mae: 6.1634\n",
      "Epoch 264/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 249.5440 - mae: 6.1174\n",
      "Epoch 265/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 256.3928 - mae: 6.1919\n",
      "Epoch 266/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 266.5289 - mae: 7.5505\n",
      "Epoch 267/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 250.7699 - mae: 6.1798\n",
      "Epoch 268/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 248.7265 - mae: 5.7157\n",
      "Epoch 269/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 258.6668 - mae: 6.8465\n",
      "Epoch 270/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 249.3272 - mae: 6.2966\n",
      "Epoch 271/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.7814 - mae: 5.9437\n",
      "Epoch 272/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 251.7470 - mae: 6.1037\n",
      "Epoch 273/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.3671 - mae: 5.8881\n",
      "Epoch 274/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 269.1518 - mae: 7.3100\n",
      "Epoch 275/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 287.9388 - mae: 9.2400\n",
      "Epoch 276/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.7709 - mae: 7.5935\n",
      "Epoch 277/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 260.0068 - mae: 7.3497\n",
      "Epoch 278/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 244.1186 - mae: 5.9625\n",
      "Epoch 279/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 246.6913 - mae: 6.1538\n",
      "Epoch 280/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 244.2690 - mae: 5.8169\n",
      "Epoch 281/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.7849 - mae: 6.2604\n",
      "Epoch 282/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.1817 - mae: 6.8402\n",
      "Epoch 283/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.8075 - mae: 8.6048\n",
      "Epoch 284/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.2651 - mae: 7.3619\n",
      "Epoch 285/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 254.8845 - mae: 6.8985\n",
      "Epoch 286/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.2786 - mae: 8.0782\n",
      "Epoch 287/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.7400 - mae: 6.7204\n",
      "Epoch 288/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 249.3020 - mae: 7.2364\n",
      "Epoch 289/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 260.2309 - mae: 7.1198\n",
      "Epoch 290/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 290.0067 - mae: 8.3458\n",
      "Epoch 291/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.3035 - mae: 8.2426\n",
      "Epoch 292/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.0026 - mae: 6.9038\n",
      "Epoch 293/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.2724 - mae: 6.4473\n",
      "Epoch 294/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.6203 - mae: 6.5933\n",
      "Epoch 295/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 238.7731 - mae: 5.9518\n",
      "Epoch 296/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 237.3760 - mae: 5.8155\n",
      "Epoch 297/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.4669 - mae: 6.0022\n",
      "Epoch 298/500\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 242.9403 - mae: 6.1315\n",
      "Epoch 299/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 232.2725 - mae: 5.8424\n",
      "Epoch 300/500\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 238.5273 - mae: 6.6921\n",
      "Epoch 301/500\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 246.5235 - mae: 7.5123\n",
      "Epoch 302/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 250.3624 - mae: 6.8536\n",
      "Epoch 303/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.8382 - mae: 5.7391\n",
      "Epoch 304/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 234.0900 - mae: 5.9561\n",
      "Epoch 305/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.8860 - mae: 5.6390\n",
      "Epoch 306/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.0440 - mae: 6.6643\n",
      "Epoch 307/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 275.4034 - mae: 8.7150\n",
      "Epoch 308/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.6945 - mae: 7.3463\n",
      "Epoch 309/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.0870 - mae: 7.6209\n",
      "Epoch 310/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 249.6718 - mae: 7.3527\n",
      "Epoch 311/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.2587 - mae: 5.7772\n",
      "Epoch 312/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 226.2819 - mae: 5.4609\n",
      "Epoch 313/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 231.1609 - mae: 5.6890\n",
      "Epoch 314/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 230.9348 - mae: 5.6926\n",
      "Epoch 315/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.2981 - mae: 5.3945\n",
      "Epoch 316/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 226.7366 - mae: 5.9515\n",
      "Epoch 317/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.0053 - mae: 5.8085\n",
      "Epoch 318/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.3327 - mae: 5.4076\n",
      "Epoch 319/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 226.8416 - mae: 6.1796\n",
      "Epoch 320/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 235.1036 - mae: 6.4989\n",
      "Epoch 321/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 226.2091 - mae: 5.5749\n",
      "Epoch 322/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.0904 - mae: 6.0917\n",
      "Epoch 323/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.9877 - mae: 6.1992\n",
      "Epoch 324/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 232.6663 - mae: 6.9359\n",
      "Epoch 325/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.3550 - mae: 5.6275\n",
      "Epoch 326/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.0985 - mae: 5.9982\n",
      "Epoch 327/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.0434 - mae: 5.9684\n",
      "Epoch 328/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 232.6948 - mae: 6.0063\n",
      "Epoch 329/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 231.4844 - mae: 6.9978\n",
      "Epoch 330/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 231.3579 - mae: 7.0298\n",
      "Epoch 331/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 224.3330 - mae: 6.4112\n",
      "Epoch 332/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 224.9279 - mae: 5.6906\n",
      "Epoch 333/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 214.5726 - mae: 5.1878\n",
      "Epoch 334/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.0665 - mae: 5.7137\n",
      "Epoch 335/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 222.2796 - mae: 5.9772\n",
      "Epoch 336/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 218.5930 - mae: 5.7532\n",
      "Epoch 337/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 214.1251 - mae: 5.1637\n",
      "Epoch 338/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 216.4374 - mae: 6.0688\n",
      "Epoch 339/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 213.9937 - mae: 5.5583\n",
      "Epoch 340/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 210.1459 - mae: 5.6593\n",
      "Epoch 341/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 215.7383 - mae: 6.0597\n",
      "Epoch 342/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.1344 - mae: 5.3411\n",
      "Epoch 343/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.8122 - mae: 5.5642\n",
      "Epoch 344/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 223.1714 - mae: 6.4696\n",
      "Epoch 345/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 221.9892 - mae: 6.5132\n",
      "Epoch 346/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 224.1723 - mae: 6.2423\n",
      "Epoch 347/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 231.2474 - mae: 7.5268\n",
      "Epoch 348/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 230.8791 - mae: 7.1761\n",
      "Epoch 349/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.6916 - mae: 8.0994\n",
      "Epoch 350/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 218.6993 - mae: 6.5784\n",
      "Epoch 351/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.9109 - mae: 5.5124\n",
      "Epoch 352/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.5374 - mae: 6.9976\n",
      "Epoch 353/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.6868 - mae: 6.8999\n",
      "Epoch 354/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.3496 - mae: 6.0792\n",
      "Epoch 355/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.1734 - mae: 7.5629\n",
      "Epoch 356/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.8799 - mae: 6.7999\n",
      "Epoch 357/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 207.8491 - mae: 5.9379\n",
      "Epoch 358/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 209.5884 - mae: 5.9417\n",
      "Epoch 359/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 207.1112 - mae: 5.6375\n",
      "Epoch 360/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.2126 - mae: 5.3279\n",
      "Epoch 361/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.4635 - mae: 5.8400\n",
      "Epoch 362/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 205.9829 - mae: 5.4270\n",
      "Epoch 363/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 215.8729 - mae: 6.4466\n",
      "Epoch 364/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 212.9365 - mae: 6.7907\n",
      "Epoch 365/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 211.7772 - mae: 5.9129\n",
      "Epoch 366/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 259.5772 - mae: 8.9525\n",
      "Epoch 367/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 253.7880 - mae: 8.4050\n",
      "Epoch 368/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 223.3719 - mae: 7.2887\n",
      "Epoch 369/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 221.9300 - mae: 6.7097\n",
      "Epoch 370/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 205.1773 - mae: 5.6807\n",
      "Epoch 371/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 205.8520 - mae: 5.6776\n",
      "Epoch 372/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 203.8061 - mae: 5.4208\n",
      "Epoch 373/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 204.7431 - mae: 5.3006\n",
      "Epoch 374/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 208.7421 - mae: 6.0348\n",
      "Epoch 375/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 231.2235 - mae: 6.3535\n",
      "Epoch 376/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 222.6910 - mae: 6.6694\n",
      "Epoch 377/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 217.4734 - mae: 6.8417\n",
      "Epoch 378/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 195.3120 - mae: 5.2997\n",
      "Epoch 379/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 201.8979 - mae: 5.8257\n",
      "Epoch 380/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 201.2535 - mae: 5.0788\n",
      "Epoch 381/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 202.7451 - mae: 6.0842\n",
      "Epoch 382/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.7278 - mae: 7.9498\n",
      "Epoch 383/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 234.5325 - mae: 8.2358\n",
      "Epoch 384/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 206.0400 - mae: 5.7585\n",
      "Epoch 385/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 195.5111 - mae: 5.1951\n",
      "Epoch 386/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 196.0176 - mae: 5.1821\n",
      "Epoch 387/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 198.8261 - mae: 5.3480\n",
      "Epoch 388/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 193.5495 - mae: 5.3073\n",
      "Epoch 389/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 192.6860 - mae: 5.3230\n",
      "Epoch 390/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.7374 - mae: 6.1289\n",
      "Epoch 391/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 226.0655 - mae: 7.5648\n",
      "Epoch 392/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 220.5892 - mae: 6.9434\n",
      "Epoch 393/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 218.3790 - mae: 7.8009\n",
      "Epoch 394/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.4340 - mae: 6.6294\n",
      "Epoch 395/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 223.5399 - mae: 6.5901\n",
      "Epoch 396/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 207.1490 - mae: 6.8943\n",
      "Epoch 397/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 222.7448 - mae: 7.4324\n",
      "Epoch 398/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 219.2686 - mae: 6.4660\n",
      "Epoch 399/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 206.0424 - mae: 7.3509\n",
      "Epoch 400/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 202.8348 - mae: 6.9405\n",
      "Epoch 401/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 196.1371 - mae: 5.5160\n",
      "Epoch 402/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 194.8398 - mae: 5.6048\n",
      "Epoch 403/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 193.0352 - mae: 5.9605\n",
      "Epoch 404/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.5716 - mae: 6.2341\n",
      "Epoch 405/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 207.2185 - mae: 6.9311\n",
      "Epoch 406/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.8060 - mae: 5.5165\n",
      "Epoch 407/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 200.9095 - mae: 6.3767\n",
      "Epoch 408/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.5670 - mae: 6.5765\n",
      "Epoch 409/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 185.1526 - mae: 4.9111\n",
      "Epoch 410/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 188.9696 - mae: 5.2625\n",
      "Epoch 411/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 187.7703 - mae: 5.2962\n",
      "Epoch 412/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 196.3879 - mae: 5.6419\n",
      "Epoch 413/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 184.1276 - mae: 5.3205\n",
      "Epoch 414/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 186.6849 - mae: 5.1793\n",
      "Epoch 415/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 184.9107 - mae: 5.4676\n",
      "Epoch 416/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 190.6837 - mae: 5.4138\n",
      "Epoch 417/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 182.6581 - mae: 4.9697\n",
      "Epoch 418/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 183.7134 - mae: 5.1017\n",
      "Epoch 419/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 188.8971 - mae: 5.1237\n",
      "Epoch 420/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 185.0732 - mae: 5.3291\n",
      "Epoch 421/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 188.8275 - mae: 5.4460\n",
      "Epoch 422/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 186.8925 - mae: 5.4970\n",
      "Epoch 423/500\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 196.4635 - mae: 6.0545\n",
      "Epoch 424/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.0413 - mae: 6.4099\n",
      "Epoch 425/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 185.4601 - mae: 4.9651\n",
      "Epoch 426/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 185.5755 - mae: 5.7410\n",
      "Epoch 427/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.3014 - mae: 5.7981\n",
      "Epoch 428/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 187.0046 - mae: 5.7278\n",
      "Epoch 429/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.4708 - mae: 6.3217\n",
      "Epoch 430/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 182.7632 - mae: 5.2736\n",
      "Epoch 431/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 180.4555 - mae: 4.9253\n",
      "Epoch 432/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.9890 - mae: 4.7597\n",
      "Epoch 433/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.5677 - mae: 5.1212\n",
      "Epoch 434/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 175.6952 - mae: 4.9386\n",
      "Epoch 435/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.3715 - mae: 5.1678\n",
      "Epoch 436/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 175.8521 - mae: 5.0543\n",
      "Epoch 437/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 183.3961 - mae: 5.1306\n",
      "Epoch 438/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 187.0412 - mae: 6.2554\n",
      "Epoch 439/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.4234 - mae: 4.9219\n",
      "Epoch 440/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 180.2727 - mae: 5.7008\n",
      "Epoch 441/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 173.1370 - mae: 5.0783\n",
      "Epoch 442/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 180.1873 - mae: 4.9613\n",
      "Epoch 443/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 209.3139 - mae: 7.4952\n",
      "Epoch 444/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.4551 - mae: 6.8518\n",
      "Epoch 445/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 188.0013 - mae: 5.8752\n",
      "Epoch 446/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.2849 - mae: 5.2647\n",
      "Epoch 447/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 174.1987 - mae: 4.9683\n",
      "Epoch 448/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 169.9509 - mae: 4.6981\n",
      "Epoch 449/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 170.8842 - mae: 5.0735\n",
      "Epoch 450/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 169.3237 - mae: 4.7940\n",
      "Epoch 451/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 172.8668 - mae: 5.0555\n",
      "Epoch 452/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 170.9827 - mae: 5.3938\n",
      "Epoch 453/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 170.8933 - mae: 5.3487\n",
      "Epoch 454/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 173.3350 - mae: 5.6160\n",
      "Epoch 455/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 187.5861 - mae: 6.0950\n",
      "Epoch 456/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 189.3444 - mae: 7.0379\n",
      "Epoch 457/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 171.5490 - mae: 5.9449\n",
      "Epoch 458/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 175.2033 - mae: 5.2358\n",
      "Epoch 459/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 178.2461 - mae: 5.7873\n",
      "Epoch 460/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 170.3643 - mae: 4.9732\n",
      "Epoch 461/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 172.0627 - mae: 5.5023\n",
      "Epoch 462/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 167.6704 - mae: 5.0656\n",
      "Epoch 463/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 163.9162 - mae: 4.5552\n",
      "Epoch 464/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 168.1705 - mae: 4.9149\n",
      "Epoch 465/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 165.9677 - mae: 5.1706\n",
      "Epoch 466/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 167.3657 - mae: 5.2098\n",
      "Epoch 467/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.4537 - mae: 6.1432\n",
      "Epoch 468/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.5752 - mae: 6.0736\n",
      "Epoch 469/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 177.7247 - mae: 6.1511\n",
      "Epoch 470/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 163.0264 - mae: 4.8940\n",
      "Epoch 471/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.4030 - mae: 6.2032\n",
      "Epoch 472/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 174.7809 - mae: 6.2245\n",
      "Epoch 473/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.9575 - mae: 6.7653\n",
      "Epoch 474/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 173.6264 - mae: 6.4258\n",
      "Epoch 475/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 166.1184 - mae: 5.0986\n",
      "Epoch 476/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 169.7208 - mae: 5.0653\n",
      "Epoch 477/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 162.1836 - mae: 4.9774\n",
      "Epoch 478/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 161.1739 - mae: 4.8501\n",
      "Epoch 479/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 173.7695 - mae: 5.4214\n",
      "Epoch 480/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 172.6723 - mae: 6.3637\n",
      "Epoch 481/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.1881 - mae: 5.4840\n",
      "Epoch 482/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.7751 - mae: 5.0040\n",
      "Epoch 483/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 156.4698 - mae: 4.4571\n",
      "Epoch 484/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.7370 - mae: 4.6826\n",
      "Epoch 485/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.7175 - mae: 4.9087\n",
      "Epoch 486/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 155.0809 - mae: 4.7150\n",
      "Epoch 487/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 161.9312 - mae: 5.1600\n",
      "Epoch 488/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.1761 - mae: 4.9372\n",
      "Epoch 489/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 158.4982 - mae: 5.6658\n",
      "Epoch 490/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 161.8223 - mae: 5.7023\n",
      "Epoch 491/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 157.2195 - mae: 4.8735\n",
      "Epoch 492/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 153.3848 - mae: 4.5950\n",
      "Epoch 493/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 152.4772 - mae: 4.5894\n",
      "Epoch 494/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 156.7978 - mae: 4.4226\n",
      "Epoch 495/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.0148 - mae: 7.0850\n",
      "Epoch 496/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 177.6227 - mae: 6.7317\n",
      "Epoch 497/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 155.0032 - mae: 5.2701\n",
      "Epoch 498/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 156.7710 - mae: 5.7126\n",
      "Epoch 499/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 155.4654 - mae: 5.5100\n",
      "Epoch 500/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 168.8521 - mae: 6.1504\n",
      "Best: 0.960773 using {'activation_func': 'relu', 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "0.959135 (0.012237) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.955730 (0.010209) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "0.958815 (0.010553) with: {'activation_func': 'relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.960773 (0.011414) with: {'activation_func': 'relu', 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "0.949590 (0.009390) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.949204 (0.010104) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "0.953152 (0.005018) with: {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.952225 (0.008849) with: {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "0.949650 (0.007775) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.949296 (0.004706) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "0.946365 (0.011985) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.954780 (0.005388) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "activation_funcs = ['relu', 'softplus', 'leaky_relu'] \n",
    "param_grid = dict(n_layers=[3], first_layer_nodes = [200,300], last_layer_nodes = [50, 100],  activation_func = activation_funcs)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid,n_jobs=-1, cv=3, scoring = 'r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch, optimizer, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=300, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=200, activation='relu'))\n",
    " model.add(Dense(units=100, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " # Compile model\n",
    " model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.989972 using {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.979394 (0.007517) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.968507 (0.009942) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.973238 (0.005890) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.960186 (0.009185) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.969433 (0.010934) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.963234 (0.010940) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.936675 (0.023253) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.948970 (0.014322) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.947507 (0.015602) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.941908 (0.028411) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.923316 (0.040511) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.946300 (0.023081) with: {'batch_size': 50, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.941469 (0.054621) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.989349 (0.004522) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.963740 (0.032686) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.971584 (0.010743) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.964040 (0.006579) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.953070 (0.019406) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.953207 (0.011672) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.959301 (0.008433) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.956189 (0.009723) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.972274 (0.011951) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.967156 (0.006583) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.972468 (0.009033) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.969047 (0.020593) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.988140 (0.003747) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.966326 (0.024150) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.971869 (0.008400) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.972252 (0.009961) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.972348 (0.007547) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.960318 (0.008708) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.957234 (0.012731) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.961217 (0.011172) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.979580 (0.007981) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.946945 (0.038259) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.981446 (0.010061) with: {'batch_size': 50, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.964795 (0.010056) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.947304 (0.043032) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.966115 (0.009882) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.962324 (0.006069) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.965458 (0.008512) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.962481 (0.009860) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.956052 (0.007917) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.953874 (0.009355) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.954015 (0.010949) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.965713 (0.014971) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.969833 (0.008756) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.971576 (0.008595) with: {'batch_size': 60, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.978381 (0.009549) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.951518 (0.029981) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.967869 (0.005964) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.969780 (0.008313) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.976332 (0.012263) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.970547 (0.008387) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.958225 (0.012054) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.957209 (0.011580) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.958199 (0.012348) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.967409 (0.006042) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.967903 (0.014899) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.958019 (0.023054) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.989972 (0.003881) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.970114 (0.022046) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.976565 (0.004197) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.966973 (0.008703) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.975117 (0.008619) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.967932 (0.010022) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.965339 (0.009748) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.961574 (0.011037) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.961054 (0.009954) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.976314 (0.007604) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.975718 (0.009444) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.980486 (0.011068) with: {'batch_size': 60, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.943636 (0.010826) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.959309 (0.004671) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.961341 (0.010271) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.958923 (0.011136) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.962302 (0.010644) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.959078 (0.009138) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.951239 (0.011614) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.947359 (0.012810) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.950620 (0.007513) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.963079 (0.013821) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.949090 (0.004409) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.955105 (0.005906) with: {'batch_size': 80, 'epochs': 300, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.973673 (0.019084) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.882546 (0.043653) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.974331 (0.006873) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.959733 (0.011497) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.962189 (0.010028) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.964589 (0.007609) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.956540 (0.008924) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.955331 (0.010215) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.956523 (0.012898) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.968009 (0.010142) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.963751 (0.008275) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.965638 (0.003594) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.978335 (0.005799) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.944903 (0.038526) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.953053 (0.026109) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.965504 (0.009678) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.966933 (0.010046) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.966454 (0.008566) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.962313 (0.009771) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.961000 (0.008571) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.963008 (0.008992) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.964884 (0.014806) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.970243 (0.010187) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.961659 (0.014532) with: {'batch_size': 80, 'epochs': 500, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 60, 80]\n",
    "epochs = [300, 400, 500]\n",
    "optimizer = ['RMSprop', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, model__optimizer=optimizer, optimizer__learning_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, scoring = 'r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
